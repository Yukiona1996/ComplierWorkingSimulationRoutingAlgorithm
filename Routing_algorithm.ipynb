{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"17tYlH7Lmz2YFnXi9Wy2VNbzCKv8YTR7s","timestamp":1721317644085}],"mount_file_id":"17tYlH7Lmz2YFnXi9Wy2VNbzCKv8YTR7s","authorship_tag":"ABX9TyPyNdQBIiB6trxrHUD3GGMh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","source":["pip install tensorflow-model-optimization"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3mhfH7w4rT9l","executionInfo":{"status":"ok","timestamp":1716949213031,"user_tz":-330,"elapsed":7259,"user":{"displayName":"Anuradha Prakash","userId":"06335237630581257981"}},"outputId":"40ab0f71-e7d9-492c-dc70-29a2aaddfd2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow-model-optimization in /usr/local/lib/python3.10/dist-packages (0.8.0)\n","Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.4.0)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (0.1.8)\n","Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.23.5)\n","Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.16.0)\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import struct\n","from scipy.sparse import csr_matrix\n","\n","def prune_model(model_type):\n","    if model_type == \"generator\":\n","        original_path = '/content/drive/MyDrive/DCGANmodels/finetuneC1/finaC1LungandColonCancerGenerator.h5'\n","        pruned_model_path = '/content/drive/MyDrive/DCGANmodels/pruned/LungandColonCancerGenatatorPrunedModel.h5'\n","    elif model_type == \"discriminator\":\n","        original_path = '/content/drive/MyDrive/DCGANmodels/finetuneC1/finalC1LungandColonCancerDiscriminator.h5'\n","        pruned_model_path = '/content/drive/MyDrive/DCGANmodels/pruned/LungandColonCancerDiscriminatorPrunedModel.h5'\n","    else:\n","        raise ValueError(\"Invalid model type. Choose 'Generator' or 'Discriminator'.\")\n","\n","    original_model = tf.keras.models.load_model(original_path)\n","\n","    pruning_threshold = 0.37\n","\n","    pruned_model = tf.keras.models.clone_model(original_model)\n","\n","    for layer in pruned_model.layers:\n","        if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.Dense):\n","            weights = layer.get_weights()\n","            pruned_weights = []\n","            for w in weights:\n","                threshold = np.percentile(np.abs(w), pruning_threshold * 100)\n","                pruned_w = np.where(np.abs(w) < threshold, 0.0, w)\n","                pruned_weights.append(pruned_w)\n","            layer.set_weights(pruned_weights)\n","\n","    total_param_count = original_model.count_params()\n","    pruned_param_count = sum(np.prod(w.shape) for w in pruned_model.get_weights())\n","    sparsity_percentage = np.mean([np.count_nonzero(w == 0) / w.size for w in pruned_weights]) * 100\n","\n","    # print(\"Number of parameters in the original model:\", total_param_count)\n","    # print(\"Number of parameters in the pruned model:\", pruned_param_count)\n","    # print(\"Sparsity percentage of the pruned model's weights:\", sparsity_percentage)\n","\n","    pruned_model = tf.keras.models.load_model(pruned_model_path, compile=False)\n","    pruned_model.compile()\n","\n","    return pruned_model"],"metadata":{"id":"DOv7RKuBM8Sv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import numpy as np\n","\n","# array_3d = np.array([\n","#     [[ 0.06715256,  0.02249832,  0.02895072, ...,  0.04440202, -0.01655976, -0.04388078],\n","#      [ 0.03473309, -0.06043807,  0.01735245, ..., -0.02202907, -0.06448454,  0.01639612],\n","#      [-0.0473573 ,  0.01233201, -0.02072671, ...,  0.03140628, -0.0041892 ,  0.07093197]],\n","\n","#     [[ 0.02187997,  0.03086492,  0.04409173, ...,  0.05337322,  0.01359168,  0.04372563],\n","#      [-0.05038473, -0.001738  ,  0.00395834, ..., -0.03038783,  0.06745648, -0.05602755],\n","#      [-0.05578252,  0.01507156, -0.03894692, ...,  0.03607336,  0.02079662, -0.04610587]],\n","\n","#     [[-0.04035418,  0.06329109,  0.06215158, ...,  0.01353917,  0.0293226 ,  0.02698114],\n","#      [-0.04121484,  0.05496372, -0.05980618, ..., -0.00269137, -0.04137776,  0.01189379],\n","#      [-0.07361974,  0.01781902, -0.00220644, ...,  0.05036451,  0.00818687,  0.01042236]],\n","\n","#     [[ 0.0537307 , -0.03556773, -0.00050614, ..., -0.05648738, -0.06677028,  0.04372723],\n","#      [-0.03774463,  0.00601193,  0.01931232, ...,  0.06274822, -0.02565265, -0.03993678],\n","#      [-0.04469112, -0.06838983, -0.01179312, ..., -0.07440331,  0.07464144,  0.01879468]]\n","# ])\n","# element = array_3d[3, 2, 1]\n","# print(element)"],"metadata":{"id":"SZJbE3rSttk1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def identify_zero_neurons(model, threshold, pruned_param_count_required=False):\n","    pruned_param_count = 0\n","    pruned_weights = []\n","\n","    for layer in model.layers:\n","        if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.Dense):\n","            weights = layer.get_weights()\n","            pruned_w = [np.where(np.abs(w) < threshold * np.max(np.abs(w)), 0.0, w) for w in weights]\n","            pruned_weights.extend(pruned_w)\n","            pruned_param_count += np.sum([np.count_nonzero(w) for w in pruned_w])\n","        else:\n","            pruned_weights.extend(layer.get_weights())\n","\n","    model.set_weights(pruned_weights)\n","\n","    total_param_count = model.count_params()\n","    sparsity_percentage = (1 - pruned_param_count / total_param_count) * 100\n","\n","    print(\"Number of parameters in the original model:\", total_param_count)\n","    print(\"Number of parameters in the pruned model:\", pruned_param_count)\n","    print(\"Sparsity percentage of the pruned model's weights:\", sparsity_percentage)\n","\n","    return pruned_param_count if pruned_param_count_required else total_param_count"],"metadata":{"id":"4lxfb-IxNV2u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_sparse_representation(weights):\n","    sparse_weights = []\n","    for weight_matrix in weights:\n","        sparse_matrix = csr_matrix(weight_matrix)\n","        sparse_weights.append((sparse_matrix.data, sparse_matrix.indices, sparse_matrix.indptr))\n","    return sparse_weights"],"metadata":{"id":"5hshLlGxL-yH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_weights_from_interpreter(interpreter):\n","    weights = []\n","    for tensor_details in interpreter.get_tensor_details():\n","        if \"weight\" in tensor_details['name']:\n","            tensor_data = interpreter.tensor(tensor_details['index'])()\n","            weights.append(tensor_data)\n","    return weights"],"metadata":{"id":"BzyUPN-9MEXT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def rle_encode(data):\n","    encoding = []\n","    i = 0\n","    while i < len(data):\n","        count = 1\n","        while i + 1 < len(data) and data[i] == data[i + 1]:\n","            count += 1\n","            i += 1\n","        encoding.append((data[i], count))\n","        i += 1\n","    return encoding"],"metadata":{"id":"hKUfPNErI3CQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def custom_compress(sparse_weights):\n","    compressed_weights = []\n","    for data, indices, indptr in sparse_weights:\n","        encoded_indices = rle_encode(indices)\n","        encoded_data = np.diff(data, prepend=data[0])\n","        compressed_weights.append((encoded_indices, encoded_data, indptr))\n","    return compressed_weights"],"metadata":{"id":"j0QXN78rMGkR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_compressed_weights(file_path, compressed_weights):\n","    with open(file_path, 'wb') as f:\n","        for encoded_indices, encoded_data, indptr in compressed_weights:\n","            f.write(struct.pack('I', len(encoded_indices)))\n","            f.write(struct.pack(f'{len(encoded_indices)}I', *encoded_indices))\n","            f.write(struct.pack('I', len(encoded_data)))\n","            f.write(struct.pack(f'{len(encoded_data)}f', *encoded_data))\n","            f.write(struct.pack('I', len(indptr)))\n","            f.write(struct.pack(f'{len(indptr)}I', *indptr))"],"metadata":{"id":"N_1Db-caMI4A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def custom_decompress(file_path):\n","    decompressed_weights = []\n","    with open(file_path, 'rb') as f:\n","        while True:\n","            try:\n","                indices_len = struct.unpack('I', f.read(4))[0]\n","                encoded_indices = struct.unpack(f'{indices_len}I', f.read(4 * indices_len))\n","                data_len = struct.unpack('I', f.read(4))[0]\n","                encoded_data = struct.unpack(f'{data_len}f', f.read(4 * data_len))\n","                indptr_len = struct.unpack('I', f.read(4))[0]\n","                indptr = struct.unpack(f'{indptr_len}I', f.read(4 * indptr_len))\n","\n","                indices = np.cumsum(encoded_indices)\n","                data = np.cumsum(encoded_data)\n","                decompressed_weights.append((data, indices, indptr))\n","            except:\n","                break\n","    return decompressed_weights"],"metadata":{"id":"c8xi3LYIMLeO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def set_sparse_weights(model, decompressed_weights):\n","    for layer, (data, indices, indptr) in zip(model.layers, decompressed_weights):\n","        if len(layer.get_weights()) > 0:\n","            weight_matrix = csr_matrix((data, indices, indptr), shape=layer.get_weights()[0].shape).toarray()\n","            layer.set_weights([weight_matrix])"],"metadata":{"id":"eJJO9HNKMPwS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import time\n","\n","class NoCRouter:\n","    def __init__(self, pe_array):\n","        self.pe_array = pe_array\n","        self.reconfig_executor = ReconfigurationExecutor()\n","\n","    def broadcast(self, source_data):\n","        print(\"Firing Broadcast Dataflow\")\n","        for z in range(2):\n","            for y in range(2):\n","                for x in range(2):\n","                    print(f\"Layer {z}: Data -> PE{y}{x}\")\n","                    self.reconfig_executor.activate_deactivate_pes(activate=True, indices=[(y, x, z)])\n","\n","    def unicast(self, source_data, dest_pe):\n","        print(\"Firing Unicast Dataflow\")\n","        y, x, z = dest_pe\n","        print(f\"Layer {z}: Data -> PE{y}{x}\")\n","        self.reconfig_executor.activate_deactivate_pes(activate=True, indices=[(y, x, z)])\n","\n","    def grouped_multicast(self, source_data, row):\n","        print(\"Firing Grouped Multicast Dataflow\")\n","        for z in range(2):\n","            for x in range(2):\n","                print(f\"Layer {z}: Data -> PE{row}{x}\")\n","                self.reconfig_executor.activate_deactivate_pes(activate=True, indices=[(row, x, z)])\n","\n","    def interleaved_multicast(self, source_data):\n","        print(\"Firing Interleaved Multicast Dataflow\")\n","        for z in range(2):\n","            for y in range(2):\n","                for x in range(2):\n","                    if (x + y) % 2 == 0:\n","                        print(f\"Layer {z}: Data -> PE{y}{x}\")\n","                        self.reconfig_executor.activate_deactivate_pes(activate=True, indices=[(y, x, z)])\n","\n","    def systolic_1d(self, source_data, row):\n","        print(\"Firing Systolic 1D Dataflow\")\n","        for z in range(2):\n","            for x in range(2):\n","                if x == 0:\n","                    print(f\"Layer {z}: Data -> PE{row}{x}\")\n","                else:\n","                    print(f\"Layer {z}: PE{row}{x-1} -> PE{row}{x}\")\n","                self.reconfig_executor.activate_deactivate_pes(activate=True, indices=[(row, x, z)])\n","\n","    def systolic_2d(self, source_data):\n","        print(\"Firing Systolic 2D Dataflow\")\n","        for z in range(2):\n","            for y in range(2):\n","                for x in range(2):\n","                    if x == 0 and y == 0:\n","                        print(f\"Layer {z}: Data -> PE{y}{x}\")\n","                        self.reconfig_executor.activate_deactivate_pes(activate=True, indices=[(y, x, z)])\n","                    elif x == 0:\n","                        print(f\"Layer {z}: PE{y-1}{x} -> PE{y}{x}\")\n","                        self.reconfig_executor.activate_deactivate_pes(activate=True, indices=[(y, x, z)])\n","                    elif y == 0:\n","                        print(f\"Layer {z}: PE{y}{x-1} -> PE{y}{x}\")\n","                        self.reconfig_executor.activate_deactivate_pes(activate=True, indices=[(y, x, z)])\n","                    else:\n","                        print(f\"Layer {z}: PE{y-1}{x} -> PE{y}{x}\")\n","                        print(f\"Layer {z}: PE{y}{x-1} -> PE{y}{x}\")\n","                        self.reconfig_executor.activate_deactivate_pes(activate=True, indices=[(y, x, z)])\n","\n","    def systolic_3d(self, source_data):\n","        print(\"Firing Systolic 3D Dataflow\")\n","        for z in range(2):\n","            for y in range(2):\n","                for x in range(2):\n","                    if x == 0 and y == 0 and z == 0:\n","                        print(f\"Layer {z}: Input Data -> PE{y}{x}\")\n","                        self.reconfig_executor.activate_deactivate_pes(activate=True, indices=[(y, x, z)])\n","                    elif x == 0 and y == 0:\n","                        print(f\"Layer {z}: PE{y}{x} -> PE{y}{x}\")\n","                        self.reconfig_executor.activate_deactivate_pes(activate=True, indices=[(y, x, z)])\n","                    elif x == 0:\n","                        print(f\"Layer {z}: PE{y-1}{x} -> PE{y}{x}\")\n","                        self.reconfig_executor.activate_deactivate_pes(activate=True, indices=[(y, x, z)])\n","                    elif y == 0:\n","                        print(f\"Layer {z}: PE{y}{x-1} -> PE{y}{x}\")\n","                        self.reconfig_executor.activate_deactivate_pes(activate=True, indices=[(y, x, z)])\n","                    else:\n","                        print(f\"Layer {z}: PE{y-1}{x} -> PE{y}{x}\")\n","                        self.reconfig_executor.activate_deactivate_pes(activate=True, indices=[(y, x, z)])\n","                        print(f\"Layer {z}: PE{y}{x-1} -> PE{y}{x}\")\n","                        self.reconfig_executor.activate_deactivate_pes(activate=True, indices=[(y, x, z)])\n","\n","    def parallel_systolic_2d(self, source_data):\n","        print(\"Firing Parallel Systolic 2D Dataflow\")\n","        for row in range(2):\n","            self.systolic_2d(source_data)\n","\n","    def parallel_systolic_1d(self, source_data):\n","        print(\"Firing Parallel Systolic 1D Dataflow\")\n","        for row in range(2):\n","            self.systolic_1d(source_data, row)\n","\n","class ResourceMonitor:\n","    def __init__(self, total_params):\n","        self.computation_load = 0\n","        self.memory_access_patterns = {}\n","        self.communication_traffic = 0\n","        self.total_params = total_params\n","\n","    def collect_data(self):\n","        self.computation_load = self.get_computation_load()\n","        self.memory_access_patterns = self.get_memory_access_patterns()\n","        self.communication_traffic = self.get_communication_traffic()\n","        print(\"Data collected: Computation load =\", self.computation_load, \"\\nMemory access patterns =\", self.memory_access_patterns, \", Communication traffic =\", self.communication_traffic)\n","\n","    def get_computation_load(self):\n","        return random.randint(0, self.total_params)\n","\n","    def get_memory_access_patterns(self):\n","        return 'highly_sparse' if random.random() > 0.35 else 'dense'\n","\n","    def get_communication_traffic(self):\n","        return random.randint(0, self.total_params)\n","\n","class DecisionMaker:\n","    def __init__(self, threshold):\n","        self.threshold = threshold\n","        self.reconfig_executor = ReconfigurationExecutor()\n","        self.noc_router = None  # This will be set from the DynamicReconfigurationSystem\n","\n","    def set_noc_router(self, noc_router):\n","        self.noc_router = noc_router\n","\n","    def make_decision(self, monitor):\n","        if monitor.computation_load > self.threshold:\n","            self.adjust_smart_buffers(monitor.computation_load)\n","        if monitor.communication_traffic > self.threshold:\n","            self.reallocate_bandwidth(monitor)\n","        if monitor.memory_access_patterns == 'highly_sparse':\n","            self.deactivate_specific_pes()\n","\n","    def adjust_smart_buffers(self, computation_load):\n","        if computation_load > self.threshold:\n","            print(\"Increasing buffer sizes to handle high computation load.\")\n","            self.reconfig_executor.resize_smart_buffers(32)\n","        else:\n","            print(\"Decreasing buffer sizes for efficiency.\")\n","            self.reconfig_executor.resize_smart_buffers(16)\n","\n","    def reallocate_bandwidth(self, monitor):\n","        if monitor.communication_traffic > self.threshold:\n","            if monitor.memory_access_patterns == 'highly_sparse':\n","                print(\"Reallocating bandwidth: Waiting in pipeline due to memory access bandwidth issue.\")\n","                # Call both multicast and unicast functions with delay\n","                self.noc_router.grouped_multicast(\"source_data\", row=0)  # Example row\n","                time.sleep(1)  # Simulate delay\n","                self.noc_router.unicast(\"source_data\", dest_pe=(1, 1, 1))  # Example PE\n","            else:\n","                print(\"Reallocating bandwidth: Using idle or deactivated PEs for PE access bandwidth issue.\")\n","                # Fetch the last set of deactivated PEs\n","                deactivated_pes = self.get_deactivated_pes()\n","                if self.is_complete_layer_deactivated(deactivated_pes):\n","                    print(\"One complete PE layer is deactivated.\")\n","                    self.noc_router.systolic_2d(\"source_data\")\n","                elif self.is_multiple_layers_deactivated(deactivated_pes):\n","                    print(\"More than one complete PE layer is deactivated.\")\n","                    self.noc_router.systolic_3d(\"source_data\")\n","                elif self.is_one_or_more_rows_deactivated(deactivated_pes):\n","                    print(\"One or more rows in a PE are deactivated.\")\n","                    self.noc_router.grouped_multicast(\"source_data\", row=0)  # Example row\n","                else:\n","                    print(\"Only one or more random PEs are deactivated.\")\n","                    self.noc_router.unicast(\"source_data\", dest_pe=deactivated_pes[0])  # Example PE\n","        else:\n","            print(\"Bandwidth allocation is optimal.\")\n","            self.noc_router.systolic_3d(\"source_data\")\n","\n","    def deactivate_specific_pes(self):\n","        print(\"Deactivating specific PEs based on memory access patterns.\")\n","        # Example logic to deactivate every alternate PE\n","        pes_to_deactivate = [(y, x, z) for z in range(2) for y in range(2) for x in range(2) if (x + y + z) % 2 != 0]\n","        self.reconfig_executor.activate_deactivate_pes(activate=False, indices=pes_to_deactivate)\n","\n","    def get_deactivated_pes(self):\n","        # Placeholder function to return a list of deactivated PEs\n","        # In real implementation, this should track the actual deactivated PEs\n","        return [(y, x, z) for z in range(8) for y in range(8) for x in range(8) if (x + y + z) % 2 != 0]\n","\n","    def is_complete_layer_deactivated(self, deactivated_pes):\n","        # Check if any complete layer is deactivated\n","        for z in range(2):\n","            if all((y, x, z) in deactivated_pes for y in range(2) for x in range(2)):\n","                return True\n","        return False\n","\n","    def is_multiple_layers_deactivated(self, deactivated_pes):\n","        # Check if more than one complete layer is deactivated\n","        deactivated_layers = 0\n","        for z in range(2):\n","            if all((y, x, z) in deactivated_pes for y in range(2) for x in range(2)):\n","                deactivated_layers += 1\n","        return deactivated_layers > 1\n","\n","    def is_one_or_more_rows_deactivated(self, deactivated_pes):\n","        # Check if one or more rows in any PE are deactivated\n","        for z in range(2):\n","            for y in range(2):\n","                if all((y, x, z) in deactivated_pes for x in range(8)):\n","                    return True\n","        return False\n","\n","class ReconfigurationExecutor:\n","    def execute_reconfiguration(self, size=32):\n","        self.resize_smart_buffers(size)\n","        self.reconfigure_noc()\n","        self.activate_deactivate_pes(activate=True, indices=[])\n","        print(\"Executed reconfiguration actions.\")\n","\n","    def resize_smart_buffers(self, size=32):\n","      if size >= 32:\n","        print(f\"Resizing smart buffers to {size} bits.\")\n","\n","    def reconfigure_noc(self):\n","        print(\"Reconfiguring NoC based on decision.\")\n","\n","    def activate_deactivate_pes(self, activate=True, indices=[]):\n","        for index in indices:\n","            if activate:\n","                print(f\"Activating PE at index: {index}\")\n","            else:\n","                print(f\"Dectivating PE at index: {index}\")\n","\n","class DynamicReconfigurationSystem:\n","    def __init__(self, pe_array, total_params, threshold):\n","        self.monitor = ResourceMonitor(total_params)\n","        self.decision_maker = DecisionMaker(threshold)\n","        self.reconfiguration_executor = ReconfigurationExecutor()\n","        self.noc_router = NoCRouter(pe_array)\n","        self.decision_maker.set_noc_router(self.noc_router)\n","\n","    def run(self):\n","        while True:\n","            self.monitor.collect_data()\n","            self.decision_maker.make_decision(self.monitor)\n","            self.reconfiguration_executor.execute_reconfiguration(self.monitor.computation_load)\n","            self.simulate_dataflows()\n","            break\n","\n","    def simulate_dataflows(self):\n","        source_data = \"data_location\"\n","        self.noc_router.broadcast(source_data)\n","        self.noc_router.unicast(source_data, (1, 1, 1))\n","        self.noc_router.grouped_multicast(source_data, 1)\n","        self.noc_router.interleaved_multicast(source_data)\n","        self.noc_router.systolic_1d(source_data, 0)\n","        self.noc_router.systolic_2d(source_data)\n","        self.noc_router.systolic_3d(source_data)\n","        self.noc_router.parallel_systolic_2d(source_data)\n","        self.noc_router.parallel_systolic_1d(source_data)"],"metadata":{"id":"nDo21bXDrzgd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import warnings\n","\n","# Suppress specific warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning, module='tensorflow')\n","\n","def main():\n","    model_type = \"generator\"  # or \"discriminator\"\n","    pruned_model = prune_model(model_type)\n","    threshold = 0.37\n","\n","    # Quantize the pruned model\n","    converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n","    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","    quantized_model = converter.convert()\n","\n","    # Set up TensorFlow Lite interpreter\n","    interpreter = tf.lite.Interpreter(model_content=quantized_model)\n","    interpreter.allocate_tensors()\n","\n","    # Extract sparse representations\n","    quantized_weights = extract_weights_from_interpreter(interpreter)\n","    sparse_weights = get_sparse_representation(quantized_weights)\n","\n","    # Compress the sparse weights\n","    compressed_weights = custom_compress(sparse_weights)\n","\n","    # Save the compressed weights\n","    compressed_weights_file = f'compressed_{model_type.lower()}_weights.bin'\n","    save_compressed_weights(compressed_weights_file, compressed_weights)\n","\n","    # Decompress the weights\n","    decompressed_weights = custom_decompress(compressed_weights_file)\n","\n","    # Set the decompressed weights back to the model\n","    set_sparse_weights(pruned_model, decompressed_weights)\n","\n","    # Calculate the number of zero neurons and set the threshold\n","    total_params = identify_zero_neurons(pruned_model, threshold=0.1, pruned_param_count_required=False)\n","    threshold = total_params // 2\n","\n","    # Initialize the PE array\n","    # pe_array = [[[f'PE{y}{x}{z}' for x in range(8)] for y in range(8)] for z in range(8)]\n","    pe_array = [[[f'PE{y}{x}{z}' for x in range(2)] for y in range(2)] for z in range(2)]\n","\n","    # Initialize and run the dynamic reconfiguration system\n","    dynamic_reconfig_system = DynamicReconfigurationSystem(pe_array, total_params, threshold)\n","    dynamic_reconfig_system.run()\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DWBCPsP2NXbr","executionInfo":{"status":"ok","timestamp":1716949298648,"user_tz":-330,"elapsed":10765,"user":{"displayName":"Anuradha Prakash","userId":"06335237630581257981"}},"outputId":"5f8e4a8a-96ad-44ca-9ddd-fff0fe722fbc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["Number of parameters in the original model: 7082752\n","Number of parameters in the pruned model: 4378428\n","Sparsity percentage of the pruned model's weights: 38.181825369573865\n","Data collected: Computation load = 2547533 \n","Memory access patterns = highly_sparse , Communication traffic = 3788302\n","Reallocating bandwidth: Waiting in pipeline due to memory access bandwidth issue.\n","Firing Grouped Multicast Dataflow\n","Layer 0: Data -> PE00\n","Activating PE at index: (0, 0, 0)\n","Layer 0: Data -> PE01\n","Activating PE at index: (0, 1, 0)\n","Layer 1: Data -> PE00\n","Activating PE at index: (0, 0, 1)\n","Layer 1: Data -> PE01\n","Activating PE at index: (0, 1, 1)\n","Firing Unicast Dataflow\n","Layer 1: Data -> PE11\n","Activating PE at index: (1, 1, 1)\n","Deactivating specific PEs based on memory access patterns.\n","Dectivating PE at index: (0, 1, 0)\n","Dectivating PE at index: (1, 0, 0)\n","Dectivating PE at index: (0, 0, 1)\n","Dectivating PE at index: (1, 1, 1)\n","Resizing smart buffers to 2547533 bits.\n","Reconfiguring NoC based on decision.\n","Executed reconfiguration actions.\n","Firing Broadcast Dataflow\n","Layer 0: Data -> PE00\n","Activating PE at index: (0, 0, 0)\n","Layer 0: Data -> PE01\n","Activating PE at index: (0, 1, 0)\n","Layer 0: Data -> PE10\n","Activating PE at index: (1, 0, 0)\n","Layer 0: Data -> PE11\n","Activating PE at index: (1, 1, 0)\n","Layer 1: Data -> PE00\n","Activating PE at index: (0, 0, 1)\n","Layer 1: Data -> PE01\n","Activating PE at index: (0, 1, 1)\n","Layer 1: Data -> PE10\n","Activating PE at index: (1, 0, 1)\n","Layer 1: Data -> PE11\n","Activating PE at index: (1, 1, 1)\n","Firing Unicast Dataflow\n","Layer 1: Data -> PE11\n","Activating PE at index: (1, 1, 1)\n","Firing Grouped Multicast Dataflow\n","Layer 0: Data -> PE10\n","Activating PE at index: (1, 0, 0)\n","Layer 0: Data -> PE11\n","Activating PE at index: (1, 1, 0)\n","Layer 1: Data -> PE10\n","Activating PE at index: (1, 0, 1)\n","Layer 1: Data -> PE11\n","Activating PE at index: (1, 1, 1)\n","Firing Interleaved Multicast Dataflow\n","Layer 0: Data -> PE00\n","Activating PE at index: (0, 0, 0)\n","Layer 0: Data -> PE11\n","Activating PE at index: (1, 1, 0)\n","Layer 1: Data -> PE00\n","Activating PE at index: (0, 0, 1)\n","Layer 1: Data -> PE11\n","Activating PE at index: (1, 1, 1)\n","Firing Systolic 1D Dataflow\n","Layer 0: Data -> PE00\n","Activating PE at index: (0, 0, 0)\n","Layer 0: PE00 -> PE01\n","Activating PE at index: (0, 1, 0)\n","Layer 1: Data -> PE00\n","Activating PE at index: (0, 0, 1)\n","Layer 1: PE00 -> PE01\n","Activating PE at index: (0, 1, 1)\n","Firing Systolic 2D Dataflow\n","Layer 0: Data -> PE00\n","Activating PE at index: (0, 0, 0)\n","Layer 0: PE00 -> PE01\n","Activating PE at index: (0, 1, 0)\n","Layer 0: PE00 -> PE10\n","Activating PE at index: (1, 0, 0)\n","Layer 0: PE01 -> PE11\n","Layer 0: PE10 -> PE11\n","Activating PE at index: (1, 1, 0)\n","Layer 1: Data -> PE00\n","Activating PE at index: (0, 0, 1)\n","Layer 1: PE00 -> PE01\n","Activating PE at index: (0, 1, 1)\n","Layer 1: PE00 -> PE10\n","Activating PE at index: (1, 0, 1)\n","Layer 1: PE01 -> PE11\n","Layer 1: PE10 -> PE11\n","Activating PE at index: (1, 1, 1)\n","Firing Systolic 3D Dataflow\n","Layer 0: Input Data -> PE00\n","Activating PE at index: (0, 0, 0)\n","Layer 0: PE00 -> PE01\n","Activating PE at index: (0, 1, 0)\n","Layer 0: PE00 -> PE10\n","Activating PE at index: (1, 0, 0)\n","Layer 0: PE01 -> PE11\n","Activating PE at index: (1, 1, 0)\n","Layer 0: PE10 -> PE11\n","Activating PE at index: (1, 1, 0)\n","Layer 1: PE00 -> PE00\n","Activating PE at index: (0, 0, 1)\n","Layer 1: PE00 -> PE01\n","Activating PE at index: (0, 1, 1)\n","Layer 1: PE00 -> PE10\n","Activating PE at index: (1, 0, 1)\n","Layer 1: PE01 -> PE11\n","Activating PE at index: (1, 1, 1)\n","Layer 1: PE10 -> PE11\n","Activating PE at index: (1, 1, 1)\n","Firing Parallel Systolic 2D Dataflow\n","Firing Systolic 2D Dataflow\n","Layer 0: Data -> PE00\n","Activating PE at index: (0, 0, 0)\n","Layer 0: PE00 -> PE01\n","Activating PE at index: (0, 1, 0)\n","Layer 0: PE00 -> PE10\n","Activating PE at index: (1, 0, 0)\n","Layer 0: PE01 -> PE11\n","Layer 0: PE10 -> PE11\n","Activating PE at index: (1, 1, 0)\n","Layer 1: Data -> PE00\n","Activating PE at index: (0, 0, 1)\n","Layer 1: PE00 -> PE01\n","Activating PE at index: (0, 1, 1)\n","Layer 1: PE00 -> PE10\n","Activating PE at index: (1, 0, 1)\n","Layer 1: PE01 -> PE11\n","Layer 1: PE10 -> PE11\n","Activating PE at index: (1, 1, 1)\n","Firing Systolic 2D Dataflow\n","Layer 0: Data -> PE00\n","Activating PE at index: (0, 0, 0)\n","Layer 0: PE00 -> PE01\n","Activating PE at index: (0, 1, 0)\n","Layer 0: PE00 -> PE10\n","Activating PE at index: (1, 0, 0)\n","Layer 0: PE01 -> PE11\n","Layer 0: PE10 -> PE11\n","Activating PE at index: (1, 1, 0)\n","Layer 1: Data -> PE00\n","Activating PE at index: (0, 0, 1)\n","Layer 1: PE00 -> PE01\n","Activating PE at index: (0, 1, 1)\n","Layer 1: PE00 -> PE10\n","Activating PE at index: (1, 0, 1)\n","Layer 1: PE01 -> PE11\n","Layer 1: PE10 -> PE11\n","Activating PE at index: (1, 1, 1)\n","Firing Parallel Systolic 1D Dataflow\n","Firing Systolic 1D Dataflow\n","Layer 0: Data -> PE00\n","Activating PE at index: (0, 0, 0)\n","Layer 0: PE00 -> PE01\n","Activating PE at index: (0, 1, 0)\n","Layer 1: Data -> PE00\n","Activating PE at index: (0, 0, 1)\n","Layer 1: PE00 -> PE01\n","Activating PE at index: (0, 1, 1)\n","Firing Systolic 1D Dataflow\n","Layer 0: Data -> PE10\n","Activating PE at index: (1, 0, 0)\n","Layer 0: PE10 -> PE11\n","Activating PE at index: (1, 1, 0)\n","Layer 1: Data -> PE10\n","Activating PE at index: (1, 0, 1)\n","Layer 1: PE10 -> PE11\n","Activating PE at index: (1, 1, 1)\n"]}]}]}